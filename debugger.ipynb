{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:32:59.856235Z",
     "start_time": "2025-02-13T13:32:58.380356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "t: GPT2Model = model.transformer"
   ],
   "id": "f416ed2eeb3bdf7d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:33:00.736153Z",
     "start_time": "2025-02-13T13:33:00.711293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Value Vector Projection\n",
    "\n",
    "def get_top_k_tokens(rep, k=5):\n",
    "    prob = torch.softmax(model.transformer.wte.weight @ rep, dim=-1)\n",
    "    prob, indices = torch.topk(prob, 5)\n",
    "    return [tokenizer.decode(i) for i in indices]\n",
    "\n",
    "def get_value_vector_tokens(layer, dim):\n",
    "    return get_top_k_tokens(t.h[layer].mlp.c_proj.weight[dim])\n",
    "\n",
    "get_value_vector_tokens(layer=17, dim=2940)"
   ],
   "id": "901b4c787e84a7be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cold', ' colder', ' precipitation', ' frost', 'clone']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:15:05.976641Z",
     "start_time": "2025-02-13T13:15:05.973402Z"
    }
   },
   "cell_type": "code",
   "source": "t.h[17].mlp.c_fc",
   "id": "a30e04c662f64793",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1D(nf=4096, nx=1024)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T14:11:24.719613Z",
     "start_time": "2025-02-13T14:11:24.717164Z"
    }
   },
   "cell_type": "code",
   "source": "t.h[0].mlp.act",
   "id": "4fc8032152697db4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewGELUActivation()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T04:52:56.297124Z",
     "start_time": "2025-02-14T04:52:54.961801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before and After Layer Representation\n",
    "# Dominant Sub Updates\n",
    "# Intervention\n",
    "\n",
    "# interventions = {\n",
    "#     10: [3141],\n",
    "#     17: [115]\n",
    "# }\n",
    "\n",
    "interventions = {}\n",
    "\n",
    "def hook(_, args, output, idx):\n",
    "    input_vec = args[0][0,-1,:]\n",
    "    output_vec = output[0][0,-1,:]\n",
    "    print(f\"Input: {get_top_k_tokens(t.ln_f(input_vec))}\")\n",
    "    print(f\"Output: {get_top_k_tokens(t.ln_f(output_vec))}\")\n",
    "    \n",
    "def proj_hook(module, args, output, idx):\n",
    "    coeff_vec = args[0][0,-1,:]\n",
    "    value_norms = torch.linalg.norm(module.weight.data, dim=1)\n",
    "    scaled_coefs = torch.absolute(coeff_vec) * value_norms\n",
    "    if idx not in interventions:\n",
    "        print(f\"\\n------Layer {idx}------\")\n",
    "    subupdates = list(enumerate(scaled_coefs))\n",
    "    subupdates = sorted(subupdates, key=lambda x: x[1], reverse=True)\n",
    "    subupdates = [f\"L{idx}D{dim}: {val:.2f}\" for dim, val in subupdates[:10]]\n",
    "    print(f\"Dominant sub updates: {subupdates[:10]}\")\n",
    "    \n",
    "def intervene_hook(module, args, output, idx):\n",
    "    if idx not in interventions:\n",
    "        return\n",
    "    print(f\"\\n------Layer {idx}------\")\n",
    "    print(f\"Intervention(s) at layer {idx}: {[f\"L{idx}D{dim}\" for dim in interventions[idx]]}\")\n",
    "    coeff_vec = output[0,-1,:]\n",
    "    # coeff_vec = t.h[idx].mlp.act(coeff_vec)\n",
    "    c_proj = t.h[idx].mlp.c_proj\n",
    "    value_norms = torch.linalg.norm(c_proj.weight.data, dim=1)\n",
    "    scaled_coefs = torch.absolute(coeff_vec) * value_norms\n",
    "    max_coeff = torch.max(scaled_coefs)\n",
    "    for dim in interventions[idx]:\n",
    "        output[0,-1,dim] = max_coeff\n",
    "    return output\n",
    "        \n",
    "        \n",
    "\n",
    "hooks = []\n",
    "for i, layer in enumerate(t.h[:]):\n",
    "    h1 = layer.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: hook(module, args, output, idx)\n",
    "    )\n",
    "    h2 = layer.mlp.c_proj.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: proj_hook(module, args, output, idx)\n",
    "    )\n",
    "    h3 = layer.mlp.c_fc.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: intervene_hook(module, args, output, idx)\n",
    "    )\n",
    "    \n",
    "    hooks.append(h1)\n",
    "    hooks.append(h2)\n",
    "    hooks.append(h3)\n",
    "\n",
    "try:\n",
    "    # Run the model to get outputs and capture intermediate representations\n",
    "    input = tokenizer.encode(\"My wife is working as a\", return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input)\n",
    "    logits = outputs.logits\n",
    "    generated_ids = torch.argmax(logits, dim=-1)\n",
    "    generated_text = tokenizer.decode(generated_ids[0][-1])\n",
    "    print(f\"\\nGenerated next token: {generated_text}\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Remove the hooks\n",
    "for h in hooks:\n",
    "    h.remove()"
   ],
   "id": "a557b60a47ac887a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Layer 0------\n",
      "Dominant sub updates: ['L0D366: 21.29', 'L0D1198: 19.19', 'L0D4055: 16.59', 'L0D798: 13.89', 'L0D1254: 12.90', 'L0D284: 10.89', 'L0D2121: 9.05', 'L0D3969: 7.66', 'L0D1619: 7.31', 'L0D2938: 6.82']\n",
      "Input: [' unden', ' helicop', ' streng', ' enthusi', ' notor']\n",
      "Output: [' completely', ' \"', ' fully', ' particularly', ' certain']\n",
      "\n",
      "------Layer 1------\n",
      "Dominant sub updates: ['L1D3460: 9.68', 'L1D736: 7.85', 'L1D51: 4.03', 'L1D676: 3.57', 'L1D1922: 3.43', 'L1D1091: 3.00', 'L1D2945: 2.57', 'L1D2023: 2.36', 'L1D3026: 2.22', 'L1D3205: 1.98']\n",
      "Input: [' completely', ' \"', ' fully', ' particularly', ' certain']\n",
      "Output: [' particularly', ' \"', ' single', ' completely', ' fully']\n",
      "\n",
      "------Layer 2------\n",
      "Dominant sub updates: ['L2D609: 2.94', 'L2D2718: 2.57', 'L2D2520: 2.20', 'L2D3131: 2.19', 'L2D3524: 2.00', 'L2D3857: 1.71', 'L2D2102: 1.18', 'L2D2107: 1.12', 'L2D1651: 1.07', 'L2D1789: 1.01']\n",
      "Input: [' particularly', ' \"', ' single', ' completely', ' fully']\n",
      "Output: [' particularly', ' single', ' \"', ' piece', ' very']\n",
      "\n",
      "------Layer 3------\n",
      "Dominant sub updates: ['L3D1791: 7.28', 'L3D2421: 2.98', 'L3D1845: 2.72', 'L3D3206: 2.05', 'L3D2077: 2.04', 'L3D1642: 1.60', 'L3D1214: 1.58', 'L3D3131: 1.58', 'L3D161: 1.56', 'L3D1157: 1.55']\n",
      "Input: [' particularly', ' single', ' \"', ' piece', ' very']\n",
      "Output: [' separate', ' very', ' single', ' well', ' particularly']\n",
      "\n",
      "------Layer 4------\n",
      "Dominant sub updates: ['L4D1501: 5.65', 'L4D3930: 5.19', 'L4D2382: 3.93', 'L4D597: 3.68', 'L4D1832: 3.14', 'L4D1751: 3.03', 'L4D3744: 2.83', 'L4D2152: 2.81', 'L4D1222: 2.69', 'L4D2764: 2.62']\n",
      "Input: [' separate', ' very', ' single', ' well', ' particularly']\n",
      "Output: [' separate', ' member', ' part', ' single', ' well']\n",
      "\n",
      "------Layer 5------\n",
      "Dominant sub updates: ['L5D1257: 5.59', 'L5D3335: 4.87', 'L5D549: 4.64', 'L5D54: 4.55', 'L5D198: 4.11', 'L5D2365: 3.98', 'L5D3094: 3.85', 'L5D2667: 3.75', 'L5D686: 3.44', 'L5D2007: 3.39']\n",
      "Input: [' separate', ' member', ' part', ' single', ' well']\n",
      "Output: [' member', ' part', ' separate', ' host', ' single']\n",
      "\n",
      "------Layer 6------\n",
      "Dominant sub updates: ['L6D3212: 6.77', 'L6D3375: 6.26', 'L6D859: 5.00', 'L6D301: 4.36', 'L6D1556: 4.34', 'L6D758: 4.33', 'L6D3141: 4.21', 'L6D1243: 4.12', 'L6D1687: 3.94', 'L6D3888: 3.18']\n",
      "Input: [' member', ' part', ' separate', ' host', ' single']\n",
      "Output: [' part', ' separate', ' member', ' full', ' very']\n",
      "\n",
      "------Layer 7------\n",
      "Dominant sub updates: ['L7D1556: 7.95', 'L7D1187: 6.36', 'L7D3765: 5.79', 'L7D2072: 5.68', 'L7D1025: 5.13', 'L7D1146: 4.11', 'L7D4017: 4.09', 'L7D2031: 4.01', 'L7D2437: 3.97', 'L7D414: 3.81']\n",
      "Input: [' part', ' separate', ' member', ' full', ' very']\n",
      "Output: [' part', ' separate', ' parallel', ' well', ' member']\n",
      "\n",
      "------Layer 8------\n",
      "Dominant sub updates: ['L8D1841: 5.22', 'L8D3929: 4.41', 'L8D1055: 4.11', 'L8D593: 3.27', 'L8D2179: 3.26', 'L8D906: 3.25', 'L8D251: 3.07', 'L8D2097: 3.00', 'L8D1637: 2.94', 'L8D2065: 2.94']\n",
      "Input: [' part', ' separate', ' parallel', ' well', ' member']\n",
      "Output: [' part', ' well', ' consultant', ' regular', ' full']\n",
      "\n",
      "------Layer 9------\n",
      "Dominant sub updates: ['L9D1752: 12.75', 'L9D3216: 8.07', 'L9D1903: 5.31', 'L9D854: 5.16', 'L9D3043: 4.79', 'L9D1589: 4.23', 'L9D1692: 3.70', 'L9D1584: 3.59', 'L9D3855: 3.23', 'L9D813: 2.96']\n",
      "Input: [' part', ' well', ' consultant', ' regular', ' full']\n",
      "Output: [' part', ' well', ' consultant', ' member', ' non']\n",
      "\n",
      "------Layer 10------\n",
      "Dominant sub updates: ['L10D3095: 6.33', 'L10D2673: 6.13', 'L10D2947: 5.36', 'L10D1598: 5.10', 'L10D3883: 4.84', 'L10D1499: 4.09', 'L10D485: 3.86', 'L10D3348: 3.83', 'L10D4048: 3.78', 'L10D3243: 3.78']\n",
      "Input: [' part', ' well', ' consultant', ' member', ' non']\n",
      "Output: [' part', ' well', ' full', ' member', ' non']\n",
      "\n",
      "------Layer 11------\n",
      "Dominant sub updates: ['L11D668: 8.05', 'L11D1467: 6.36', 'L11D3184: 5.93', 'L11D2401: 5.82', 'L11D2918: 5.11', 'L11D3280: 4.67', 'L11D3014: 4.50', 'L11D2218: 3.96', 'L11D2207: 3.63', 'L11D734: 3.59']\n",
      "Input: [' part', ' well', ' full', ' member', ' non']\n",
      "Output: [' part', ' full', ' non', ' member', ' well']\n",
      "\n",
      "------Layer 12------\n",
      "Dominant sub updates: ['L12D661: 8.70', 'L12D591: 7.15', 'L12D103: 6.08', 'L12D3948: 5.60', 'L12D97: 5.56', 'L12D220: 5.10', 'L12D772: 4.83', 'L12D3118: 4.45', 'L12D2977: 4.26', 'L12D2342: 4.21']\n",
      "Input: [' part', ' full', ' non', ' member', ' well']\n",
      "Output: [' consultant', ' freelance', ' part', ' full', ' non']\n",
      "\n",
      "------Layer 13------\n",
      "Dominant sub updates: ['L13D3930: 10.34', 'L13D3042: 9.98', 'L13D3926: 9.26', 'L13D2027: 7.24', 'L13D820: 6.82', 'L13D3210: 5.93', 'L13D3561: 4.46', 'L13D1489: 4.41', 'L13D2631: 4.29', 'L13D1651: 4.10']\n",
      "Input: [' consultant', ' freelance', ' part', ' full', ' non']\n",
      "Output: [' freelance', ' consultant', ' professional', ' graduate', ' non']\n",
      "\n",
      "------Layer 14------\n",
      "Dominant sub updates: ['L14D3722: 10.08', 'L14D3645: 7.78', 'L14D625: 6.86', 'L14D2287: 4.60', 'L14D3341: 4.60', 'L14D1884: 4.54', 'L14D2378: 4.38', 'L14D3094: 4.33', 'L14D202: 4.14', 'L14D3640: 4.14']\n",
      "Input: [' freelance', ' consultant', ' professional', ' graduate', ' non']\n",
      "Output: [' consultant', ' freelance', ' professional', ' volunteer', ' member']\n",
      "\n",
      "------Layer 15------\n",
      "Dominant sub updates: ['L15D701: 11.99', 'L15D109: 9.40', 'L15D1960: 7.59', 'L15D3863: 6.33', 'L15D1021: 6.00', 'L15D1167: 5.71', 'L15D3355: 5.67', 'L15D2149: 5.57', 'L15D2486: 5.14', 'L15D585: 4.92']\n",
      "Input: [' consultant', ' freelance', ' professional', ' volunteer', ' member']\n",
      "Output: [' consultant', ' freelance', ' professional', ' volunteer', ' doctor']\n",
      "\n",
      "------Layer 16------\n",
      "Dominant sub updates: ['L16D918: 16.57', 'L16D713: 11.40', 'L16D441: 9.85', 'L16D140: 9.72', 'L16D3696: 7.70', 'L16D2292: 6.47', 'L16D3726: 6.28', 'L16D2324: 6.24', 'L16D412: 5.62', 'L16D1084: 5.61']\n",
      "Input: [' consultant', ' freelance', ' professional', ' volunteer', ' doctor']\n",
      "Output: [' freelance', ' consultant', ' professional', ' waitress', ' volunteer']\n",
      "\n",
      "------Layer 17------\n",
      "Dominant sub updates: ['L17D1492: 18.25', 'L17D2518: 11.90', 'L17D188: 9.69', 'L17D442: 8.61', 'L17D1918: 8.59', 'L17D1798: 8.34', 'L17D2016: 6.61', 'L17D2948: 6.29', 'L17D1828: 5.79', 'L17D3212: 5.25']\n",
      "Input: [' freelance', ' consultant', ' professional', ' waitress', ' volunteer']\n",
      "Output: [' consultant', ' freelance', ' professional', ' waitress', ' volunteer']\n",
      "\n",
      "------Layer 18------\n",
      "Dominant sub updates: ['L18D919: 16.14', 'L18D3317: 10.12', 'L18D3511: 9.31', 'L18D1079: 8.34', 'L18D2286: 8.17', 'L18D2860: 7.93', 'L18D3331: 7.57', 'L18D646: 6.85', 'L18D1437: 6.85', 'L18D1770: 6.07']\n",
      "Input: [' consultant', ' freelance', ' professional', ' waitress', ' volunteer']\n",
      "Output: [' consultant', ' waitress', ' professional', ' freelance', ' teacher']\n",
      "\n",
      "------Layer 19------\n",
      "Dominant sub updates: ['L19D526: 18.37', 'L19D669: 17.41', 'L19D2191: 13.77', 'L19D1082: 12.68', 'L19D1451: 10.62', 'L19D2756: 10.48', 'L19D2882: 10.11', 'L19D1485: 9.59', 'L19D3176: 8.64', 'L19D998: 7.98']\n",
      "Input: [' consultant', ' waitress', ' professional', ' freelance', ' teacher']\n",
      "Output: [' waitress', ' nurse', ' consultant', ' freelance', ' teacher']\n",
      "\n",
      "------Layer 20------\n",
      "Dominant sub updates: ['L20D2820: 29.43', 'L20D2714: 19.10', 'L20D3518: 17.89', 'L20D3009: 16.13', 'L20D3818: 15.26', 'L20D3210: 12.34', 'L20D2003: 11.92', 'L20D2043: 11.63', 'L20D2850: 9.92', 'L20D1979: 9.87']\n",
      "Input: [' waitress', ' nurse', ' consultant', ' freelance', ' teacher']\n",
      "Output: [' nurse', ' waitress', ' teacher', ' consultant', ' freelance']\n",
      "\n",
      "------Layer 21------\n",
      "Dominant sub updates: ['L21D3336: 26.25', 'L21D3638: 22.41', 'L21D2886: 18.48', 'L21D1402: 17.49', 'L21D178: 13.69', 'L21D233: 13.19', 'L21D1010: 12.32', 'L21D3062: 11.92', 'L21D636: 11.83', 'L21D343: 11.51']\n",
      "Input: [' nurse', ' waitress', ' teacher', ' consultant', ' freelance']\n",
      "Output: [' nurse', ' waitress', ' teacher', ' consultant', ' lawyer']\n",
      "\n",
      "------Layer 22------\n",
      "Dominant sub updates: ['L22D3980: 51.75', 'L22D2624: 39.23', 'L22D17: 24.55', 'L22D3015: 17.34', 'L22D535: 16.56', 'L22D2679: 15.17', 'L22D1005: 14.82', 'L22D323: 14.32', 'L22D3516: 13.76', 'L22D3030: 13.12']\n",
      "Input: [' nurse', ' waitress', ' teacher', ' consultant', ' lawyer']\n",
      "Output: [' nurse', ' waitress', ' teacher', ' professional', ' lawyer']\n",
      "\n",
      "------Layer 23------\n",
      "Dominant sub updates: ['L23D3401: 37.91', 'L23D816: 37.27', 'L23D2345: 23.39', 'L23D420: 20.01', 'L23D3383: 14.04', 'L23D650: 12.37', 'L23D2614: 11.78', 'L23D2921: 11.01', 'L23D3369: 10.56', 'L23D1605: 9.84']\n",
      "Input: [' nurse', ' waitress', ' teacher', ' professional', ' lawyer']\n",
      "Output: [' nurse', ' teacher', ' waitress', ' lawyer', ' consultant']\n",
      "\n",
      "Generated next token:  nurse\n"
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
