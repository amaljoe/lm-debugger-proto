{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:08:47.943127Z",
     "start_time": "2025-02-13T13:08:42.325273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "t: GPT2Model = model.transformer"
   ],
   "id": "f416ed2eeb3bdf7d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:08:47.979405Z",
     "start_time": "2025-02-13T13:08:47.950191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Value Vector Projection\n",
    "\n",
    "def get_top_k_tokens(rep, k=5):\n",
    "    prob = torch.softmax(model.transformer.wte.weight @ rep, dim=-1)\n",
    "    prob, indices = torch.topk(prob, 5)\n",
    "    return [tokenizer.decode(i) for i in indices]\n",
    "\n",
    "def get_value_vector_tokens(layer, dim):\n",
    "    return get_top_k_tokens(t.h[layer].mlp.c_proj.weight[dim])\n",
    "\n",
    "get_value_vector_tokens(layer=17, dim=2940)"
   ],
   "id": "901b4c787e84a7be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cold', ' colder', ' precipitation', ' frost', 'clone']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T13:10:17.506582Z",
     "start_time": "2025-02-13T13:10:16.135670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before and After Layer Representation\n",
    "# Dominant Sub Updates\n",
    "# Intervention\n",
    "\n",
    "interventions = [\n",
    "    [10, 3141],\n",
    "    [17, 115]\n",
    "]\n",
    "\n",
    "def hook(_, args, output, idx):\n",
    "    input_vec = args[0][0,-1,:]\n",
    "    output_vec = output[0][0,-1,:]\n",
    "    print(f\"Input: {get_top_k_tokens(t.ln_f(input_vec))}\")\n",
    "    print(f\"Output: {get_top_k_tokens(t.ln_f(output_vec))}\")\n",
    "    \n",
    "def proj_hook(module, args, output, idx):\n",
    "    coeff_vec = args[0][0,-1,:]\n",
    "    value_norms = torch.linalg.norm(module.weight.data, dim=1)\n",
    "    scaled_coefs = torch.absolute(coeff_vec) * value_norms\n",
    "    print(f\"\\n------Layer {idx}------\")\n",
    "    subupdates = list(enumerate(scaled_coefs))\n",
    "    subupdates = sorted(subupdates, key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Dominant sub updates: {subupdates[:10]}\")\n",
    "    \n",
    "def intervene_hook(module, args, output, idx):\n",
    "    pass\n",
    "\n",
    "hooks = []\n",
    "for i, layer in enumerate(t.h[:]):\n",
    "    h1 = layer.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: hook(module, args, output, idx)\n",
    "    )\n",
    "    h2 = layer.mlp.c_proj.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: proj_hook(module, args, output, idx)\n",
    "    )\n",
    "    \n",
    "    hooks.append(h1)\n",
    "    hooks.append(h2)\n",
    "    \n",
    "try:\n",
    "    # Run the model to get outputs and capture intermediate representations\n",
    "    input = tokenizer.encode(\"Shes a good software engineer. My wife is working as a\", return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input)\n",
    "    logits = outputs.logits\n",
    "    generated_ids = torch.argmax(logits, dim=-1)\n",
    "    generated_text = tokenizer.decode(generated_ids[0][-1])\n",
    "    print(f\"\\nGenerated next token: {generated_text}\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Remove the hooks\n",
    "for h in hooks:\n",
    "    h.remove()"
   ],
   "id": "a557b60a47ac887a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Layer 0------\n",
      "Dominant sub updates: [(798, tensor(21.3829)), (1198, tensor(19.9338)), (4055, tensor(13.2137)), (1254, tensor(13.1095)), (1959, tensor(10.4864)), (2121, tensor(9.2717)), (3969, tensor(8.7648)), (366, tensor(8.1425)), (1619, tensor(8.0389)), (2938, tensor(7.1318))]\n",
      "Input: [' unden', ' helicop', ' streng', ' nodd', ' enthusi']\n",
      "Output: [' particularly', ' certain', ' particular', ' fully', ' completely']\n",
      "\n",
      "------Layer 1------\n",
      "Dominant sub updates: [(3460, tensor(9.3865)), (736, tensor(7.6379)), (51, tensor(3.2824)), (1922, tensor(2.8847)), (2023, tensor(2.8724)), (1091, tensor(2.6264)), (780, tensor(2.5216)), (676, tensor(2.2914)), (3026, tensor(1.7580)), (2302, tensor(1.5944))]\n",
      "Input: [' particularly', ' certain', ' particular', ' fully', ' completely']\n",
      "Output: [' particularly', ' \"', ' certain', ' particular', ' single']\n",
      "\n",
      "------Layer 2------\n",
      "Dominant sub updates: [(609, tensor(2.5876)), (3131, tensor(2.1844)), (2718, tensor(2.0974)), (3857, tensor(1.9912)), (2520, tensor(1.7383)), (3101, tensor(1.0012)), (366, tensor(0.9663)), (2102, tensor(0.9067)), (3224, tensor(0.9027)), (3125, tensor(0.8908))]\n",
      "Input: [' particularly', ' \"', ' certain', ' particular', ' single']\n",
      "Output: [' particularly', ' \"', ' very', ' piece', ' separate']\n",
      "\n",
      "------Layer 3------\n",
      "Dominant sub updates: [(1791, tensor(8.5171)), (1845, tensor(3.6119)), (2421, tensor(3.3284)), (161, tensor(2.0449)), (1642, tensor(2.0206)), (3206, tensor(1.8130)), (1214, tensor(1.7672)), (258, tensor(1.7012)), (2077, tensor(1.6219)), (3131, tensor(1.6131))]\n",
      "Input: [' particularly', ' \"', ' very', ' piece', ' separate']\n",
      "Output: [' separate', ' particularly', ' very', ' well', ' potential']\n",
      "\n",
      "------Layer 4------\n",
      "Dominant sub updates: [(1501, tensor(6.2137)), (2382, tensor(4.8969)), (3930, tensor(4.8946)), (597, tensor(4.1430)), (1241, tensor(3.5379)), (1222, tensor(3.0984)), (1751, tensor(3.0482)), (1832, tensor(2.8774)), (428, tensor(2.5752)), (3744, tensor(2.5314))]\n",
      "Input: [' separate', ' particularly', ' very', ' well', ' potential']\n",
      "Output: [' separate', ' member', ' well', ' part', ' non']\n",
      "\n",
      "------Layer 5------\n",
      "Dominant sub updates: [(1257, tensor(5.5590)), (686, tensor(5.4430)), (54, tensor(5.1084)), (3335, tensor(4.8040)), (549, tensor(4.6343)), (3094, tensor(3.9522)), (198, tensor(3.7373)), (2667, tensor(3.4738)), (2365, tensor(3.4156)), (2007, tensor(3.3443))]\n",
      "Input: [' separate', ' member', ' well', ' part', ' non']\n",
      "Output: [' separate', ' member', ' part', ' very', ' major']\n",
      "\n",
      "------Layer 6------\n",
      "Dominant sub updates: [(3212, tensor(6.9313)), (3375, tensor(5.9876)), (859, tensor(5.2188)), (1243, tensor(4.7444)), (1556, tensor(4.3214)), (1687, tensor(4.1443)), (301, tensor(3.7974)), (758, tensor(3.7696)), (3141, tensor(3.7342)), (977, tensor(3.2667))]\n",
      "Input: [' separate', ' member', ' part', ' very', ' major']\n",
      "Output: [' separate', ' part', ' member', ' very', ' full']\n",
      "\n",
      "------Layer 7------\n",
      "Dominant sub updates: [(3765, tensor(7.2009)), (1556, tensor(7.1459)), (1187, tensor(6.7547)), (2072, tensor(6.5669)), (1025, tensor(4.8888)), (1146, tensor(4.0043)), (414, tensor(4.0038)), (2031, tensor(3.8777)), (1567, tensor(3.4290)), (4017, tensor(3.4108))]\n",
      "Input: [' separate', ' part', ' member', ' very', ' full']\n",
      "Output: [' separate', ' part', ' parallel', ' well', ' very']\n",
      "\n",
      "------Layer 8------\n",
      "Dominant sub updates: [(1841, tensor(4.9358)), (3929, tensor(4.0164)), (906, tensor(3.9687)), (1055, tensor(3.5782)), (1691, tensor(3.4976)), (251, tensor(3.3889)), (593, tensor(3.1647)), (2179, tensor(3.0840)), (3408, tensor(2.8369)), (2065, tensor(2.8115))]\n",
      "Input: [' separate', ' part', ' parallel', ' well', ' very']\n",
      "Output: [' part', ' full', ' well', ' very', ' non']\n",
      "\n",
      "------Layer 9------\n",
      "Dominant sub updates: [(1752, tensor(17.2823)), (3216, tensor(8.3691)), (1903, tensor(4.9329)), (1584, tensor(4.3028)), (1589, tensor(4.0994)), (854, tensor(4.0658)), (1692, tensor(3.4183)), (2409, tensor(3.2672)), (1030, tensor(3.2049)), (1534, tensor(3.0958))]\n",
      "Input: [' part', ' full', ' well', ' very', ' non']\n",
      "Output: [' part', ' well', ' full', ' non', ' member']\n",
      "\n",
      "------Layer 10------\n",
      "Dominant sub updates: [(3095, tensor(6.3556)), (2673, tensor(6.3013)), (3628, tensor(6.0519)), (1598, tensor(5.4591)), (3243, tensor(5.1526)), (3883, tensor(4.8016)), (2947, tensor(4.7517)), (896, tensor(4.2971)), (3348, tensor(3.6299)), (3360, tensor(3.5993))]\n",
      "Input: [' part', ' well', ' full', ' non', ' member']\n",
      "Output: [' part', ' full', ' non', ' member', ' well']\n",
      "\n",
      "------Layer 11------\n",
      "Dominant sub updates: [(668, tensor(7.2412)), (2401, tensor(6.4131)), (3184, tensor(6.2966)), (1467, tensor(6.2896)), (2918, tensor(5.0692)), (3014, tensor(4.7063)), (3280, tensor(4.5930)), (1921, tensor(3.7677)), (1494, tensor(3.7267)), (1227, tensor(3.5128))]\n",
      "Input: [' part', ' full', ' non', ' member', ' well']\n",
      "Output: [' part', ' non', ' member', ' full', ' major']\n",
      "\n",
      "------Layer 12------\n",
      "Dominant sub updates: [(661, tensor(7.9703)), (591, tensor(6.5297)), (103, tensor(5.3218)), (220, tensor(4.6995)), (3948, tensor(4.6849)), (772, tensor(4.6239)), (97, tensor(4.3087)), (3118, tensor(4.0695)), (2977, tensor(3.8087)), (2142, tensor(3.7365))]\n",
      "Input: [' part', ' non', ' member', ' full', ' major']\n",
      "Output: [' consultant', ' non', ' part', ' full', ' member']\n",
      "\n",
      "------Layer 13------\n",
      "Dominant sub updates: [(3930, tensor(10.3324)), (3042, tensor(10.1288)), (3926, tensor(9.2669)), (2027, tensor(6.9154)), (820, tensor(5.8629)), (1489, tensor(4.5668)), (1719, tensor(4.3615)), (3210, tensor(4.0416)), (3561, tensor(3.9851)), (3583, tensor(3.9770))]\n",
      "Input: [' consultant', ' non', ' part', ' full', ' member']\n",
      "Output: [' consultant', ' freelance', ' professional', ' non', ' member']\n",
      "\n",
      "------Layer 14------\n",
      "Dominant sub updates: [(3722, tensor(9.3706)), (3645, tensor(7.3476)), (625, tensor(5.7121)), (2287, tensor(4.5284)), (35, tensor(4.5228)), (2378, tensor(4.2947)), (1884, tensor(4.2724)), (202, tensor(4.1091)), (1284, tensor(3.6411)), (491, tensor(3.6351))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' non', ' member']\n",
      "Output: [' consultant', ' professional', ' freelance', ' member', ' non']\n",
      "\n",
      "------Layer 15------\n",
      "Dominant sub updates: [(701, tensor(11.0843)), (1960, tensor(7.8290)), (109, tensor(7.4407)), (3355, tensor(5.5206)), (1021, tensor(5.1876)), (1167, tensor(4.3586)), (30, tensor(4.3033)), (2577, tensor(4.1704)), (3115, tensor(4.1259)), (869, tensor(4.0667))]\n",
      "Input: [' consultant', ' professional', ' freelance', ' member', ' non']\n",
      "Output: [' consultant', ' professional', ' freelance', ' non', ' member']\n",
      "\n",
      "------Layer 16------\n",
      "Dominant sub updates: [(918, tensor(13.2112)), (140, tensor(10.5171)), (441, tensor(9.1505)), (713, tensor(8.9200)), (3696, tensor(8.2790)), (2324, tensor(6.4719)), (1149, tensor(6.0271)), (3726, tensor(5.0431)), (2292, tensor(4.8794)), (609, tensor(4.6330))]\n",
      "Input: [' consultant', ' professional', ' freelance', ' non', ' member']\n",
      "Output: [' consultant', ' freelance', ' professional', ' freel', ' non']\n",
      "\n",
      "------Layer 17------\n",
      "Dominant sub updates: [(1492, tensor(15.6489)), (2518, tensor(10.7156)), (188, tensor(8.9486)), (1798, tensor(7.9262)), (1918, tensor(7.4200)), (442, tensor(7.4088)), (2016, tensor(6.1626)), (2948, tensor(6.1024)), (2095, tensor(5.9281)), (323, tensor(5.6299))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' freel', ' non']\n",
      "Output: [' consultant', ' freelance', ' professional', ' freel', ' tech']\n",
      "\n",
      "------Layer 18------\n",
      "Dominant sub updates: [(919, tensor(12.1026)), (3317, tensor(8.9418)), (1079, tensor(8.3975)), (2860, tensor(8.0135)), (3511, tensor(7.9566)), (2286, tensor(7.2941)), (1437, tensor(7.0959)), (2654, tensor(5.8589)), (1670, tensor(5.4836)), (809, tensor(5.4764))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' freel', ' tech']\n",
      "Output: [' consultant', ' freelance', ' professional', ' software', ' tech']\n",
      "\n",
      "------Layer 19------\n",
      "Dominant sub updates: [(526, tensor(13.6687)), (2191, tensor(12.8019)), (1082, tensor(12.3664)), (669, tensor(10.2643)), (2756, tensor(10.1329)), (1451, tensor(9.7217)), (1485, tensor(9.3869)), (702, tensor(8.2950)), (3080, tensor(8.2290)), (2485, tensor(7.8000))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' software', ' tech']\n",
      "Output: [' consultant', ' software', ' freelance', ' tech', ' programmer']\n",
      "\n",
      "------Layer 20------\n",
      "Dominant sub updates: [(2820, tensor(28.0351)), (3518, tensor(16.1132)), (2714, tensor(15.4106)), (1979, tensor(13.0488)), (3009, tensor(12.9546)), (3818, tensor(12.6442)), (3210, tensor(11.9840)), (446, tensor(10.6721)), (3874, tensor(9.7045)), (1375, tensor(9.5379))]\n",
      "Input: [' consultant', ' software', ' freelance', ' tech', ' programmer']\n",
      "Output: [' software', ' consultant', ' tech', ' programmer', ' freelance']\n",
      "\n",
      "------Layer 21------\n",
      "Dominant sub updates: [(3336, tensor(24.7339)), (3638, tensor(22.1270)), (2886, tensor(17.1715)), (1402, tensor(15.3591)), (1010, tensor(14.2839)), (739, tensor(12.6702)), (371, tensor(12.0866)), (3062, tensor(11.2821)), (343, tensor(10.1389)), (1159, tensor(9.7708))]\n",
      "Input: [' software', ' consultant', ' tech', ' programmer', ' freelance']\n",
      "Output: [' software', ' programmer', ' consultant', ' tech', ' computer']\n",
      "\n",
      "------Layer 22------\n",
      "Dominant sub updates: [(3980, tensor(41.9745)), (2624, tensor(34.1461)), (3015, tensor(16.3025)), (323, tensor(15.3936)), (2679, tensor(14.6099)), (535, tensor(13.8086)), (17, tensor(12.9081)), (3760, tensor(12.8948)), (1005, tensor(12.4950)), (3030, tensor(12.2170))]\n",
      "Input: [' software', ' programmer', ' consultant', ' tech', ' computer']\n",
      "Output: [' software', ' tech', ' programmer', ' consultant', ' computer']\n",
      "\n",
      "------Layer 23------\n",
      "Dominant sub updates: [(816, tensor(36.4325)), (3401, tensor(32.2491)), (2345, tensor(18.5065)), (420, tensor(17.3927)), (3383, tensor(14.7613)), (438, tensor(13.8329)), (897, tensor(11.5765)), (655, tensor(11.4284)), (3369, tensor(11.3084)), (3613, tensor(9.7410))]\n",
      "Input: [' software', ' tech', ' programmer', ' consultant', ' computer']\n",
      "Output: [' software', ' web', ' programmer', ' consultant', ' tech']\n",
      "\n",
      "Generated next token:  software\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
