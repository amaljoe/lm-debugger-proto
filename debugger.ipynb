{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T18:04:34.605538Z",
     "start_time": "2025-02-10T18:04:31.933335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "t: GPT2Model = model.transformer"
   ],
   "id": "f416ed2eeb3bdf7d",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T18:04:34.697433Z",
     "start_time": "2025-02-10T18:04:34.655189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Value Vector Projection\n",
    "\n",
    "def get_top_k_tokens(rep, k=5):\n",
    "    prob = torch.softmax(model.transformer.wte.weight @ rep, dim=-1)\n",
    "    prob, indices = torch.topk(prob, 5)\n",
    "    return [tokenizer.decode(i) for i in indices]\n",
    "\n",
    "def get_value_vector_tokens(layer, dim):\n",
    "    return get_top_k_tokens(t.h[layer].mlp.c_proj.weight[dim])\n",
    "\n",
    "get_value_vector_tokens(layer=17, dim=2940)"
   ],
   "id": "901b4c787e84a7be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cold', ' colder', ' precipitation', ' frost', 'clone']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T18:09:06.867114Z",
     "start_time": "2025-02-10T18:09:05.785297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Before and After Layer Representation\n",
    "\n",
    "def hook(_, args, output, idx):\n",
    "    input_vec = args[0][0,-1,:]\n",
    "    output_vec = output[0][0,-1,:]\n",
    "    print(f\"Input: {get_top_k_tokens(t.ln_f(input_vec))}\")\n",
    "    print(f\"Output: {get_top_k_tokens(t.ln_f(output_vec))}\")\n",
    "    \n",
    "def proj_hook(module, args, output, idx):\n",
    "    coeff_vec = args[0][0,-1,:]\n",
    "    value_norms = torch.linalg.norm(module.weight.data, dim=1)\n",
    "    scaled_coefs = torch.absolute(coeff_vec) * value_norms\n",
    "    print(f\"\\n------Layer {idx}------\")\n",
    "    subupdates = list(enumerate(scaled_coefs))\n",
    "    subupdates = sorted(subupdates, key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Dominant sub updates: {subupdates[:10]}\")\n",
    "\n",
    "hooks = []\n",
    "for i, layer in enumerate(t.h[:]):\n",
    "    h1 = layer.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: hook(module, args, output, idx)\n",
    "    )\n",
    "    h2 = layer.mlp.c_proj.register_forward_hook(\n",
    "        lambda module, args, output, idx=i: proj_hook(module, args, output, idx)\n",
    "    )\n",
    "    hooks.append(h1)\n",
    "    hooks.append(h2)\n",
    "    \n",
    "try:\n",
    "    # Run the model to get outputs and capture intermediate representations\n",
    "    input = tokenizer.encode(\"My wife is working as a\", return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input)\n",
    "    logits = outputs.logits\n",
    "    generated_ids = torch.argmax(logits, dim=-1)\n",
    "    generated_text = tokenizer.decode(generated_ids[0][-1])\n",
    "    print(f\"\\nGenerated next token: {generated_text}\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Remove the hooks\n",
    "for h in hooks:\n",
    "    h.remove()"
   ],
   "id": "a557b60a47ac887a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Layer 0------\n",
      "Dominant sub updates: [(366, tensor(21.2909)), (1198, tensor(19.1944)), (4055, tensor(16.5859)), (798, tensor(13.8921)), (1254, tensor(12.9030)), (284, tensor(10.8873)), (2121, tensor(9.0504)), (3969, tensor(7.6568)), (1619, tensor(7.3107)), (2938, tensor(6.8245))]\n",
      "Input: [' unden', ' helicop', ' streng', ' enthusi', ' notor']\n",
      "Output: [' completely', ' \"', ' fully', ' particularly', ' certain']\n",
      "\n",
      "------Layer 1------\n",
      "Dominant sub updates: [(3460, tensor(9.6827)), (736, tensor(7.8470)), (51, tensor(4.0347)), (676, tensor(3.5699)), (1922, tensor(3.4282)), (1091, tensor(2.9955)), (2945, tensor(2.5733)), (2023, tensor(2.3635)), (3026, tensor(2.2193)), (3205, tensor(1.9815))]\n",
      "Input: [' completely', ' \"', ' fully', ' particularly', ' certain']\n",
      "Output: [' particularly', ' \"', ' single', ' completely', ' fully']\n",
      "\n",
      "------Layer 2------\n",
      "Dominant sub updates: [(609, tensor(2.9426)), (2718, tensor(2.5653)), (2520, tensor(2.2043)), (3131, tensor(2.1944)), (3524, tensor(2.0022)), (3857, tensor(1.7079)), (2102, tensor(1.1800)), (2107, tensor(1.1212)), (1651, tensor(1.0715)), (1789, tensor(1.0050))]\n",
      "Input: [' particularly', ' \"', ' single', ' completely', ' fully']\n",
      "Output: [' particularly', ' single', ' \"', ' piece', ' very']\n",
      "\n",
      "------Layer 3------\n",
      "Dominant sub updates: [(1791, tensor(7.2793)), (2421, tensor(2.9755)), (1845, tensor(2.7151)), (3206, tensor(2.0471)), (2077, tensor(2.0403)), (1642, tensor(1.5983)), (1214, tensor(1.5837)), (3131, tensor(1.5777)), (161, tensor(1.5637)), (1157, tensor(1.5494))]\n",
      "Input: [' particularly', ' single', ' \"', ' piece', ' very']\n",
      "Output: [' separate', ' very', ' single', ' well', ' particularly']\n",
      "\n",
      "------Layer 4------\n",
      "Dominant sub updates: [(1501, tensor(5.6482)), (3930, tensor(5.1863)), (2382, tensor(3.9326)), (597, tensor(3.6847)), (1832, tensor(3.1361)), (1751, tensor(3.0315)), (3744, tensor(2.8310)), (2152, tensor(2.8104)), (1222, tensor(2.6886)), (2764, tensor(2.6232))]\n",
      "Input: [' separate', ' very', ' single', ' well', ' particularly']\n",
      "Output: [' separate', ' member', ' part', ' single', ' well']\n",
      "\n",
      "------Layer 5------\n",
      "Dominant sub updates: [(1257, tensor(5.5890)), (3335, tensor(4.8701)), (549, tensor(4.6433)), (54, tensor(4.5460)), (198, tensor(4.1062)), (2365, tensor(3.9767)), (3094, tensor(3.8476)), (2667, tensor(3.7457)), (686, tensor(3.4361)), (2007, tensor(3.3904))]\n",
      "Input: [' separate', ' member', ' part', ' single', ' well']\n",
      "Output: [' member', ' part', ' separate', ' host', ' single']\n",
      "\n",
      "------Layer 6------\n",
      "Dominant sub updates: [(3212, tensor(6.7704)), (3375, tensor(6.2578)), (859, tensor(5.0029)), (301, tensor(4.3565)), (1556, tensor(4.3380)), (758, tensor(4.3321)), (3141, tensor(4.2136)), (1243, tensor(4.1153)), (1687, tensor(3.9407)), (3888, tensor(3.1768))]\n",
      "Input: [' member', ' part', ' separate', ' host', ' single']\n",
      "Output: [' part', ' separate', ' member', ' full', ' very']\n",
      "\n",
      "------Layer 7------\n",
      "Dominant sub updates: [(1556, tensor(7.9521)), (1187, tensor(6.3617)), (3765, tensor(5.7938)), (2072, tensor(5.6778)), (1025, tensor(5.1277)), (1146, tensor(4.1130)), (4017, tensor(4.0860)), (2031, tensor(4.0136)), (2437, tensor(3.9679)), (414, tensor(3.8084))]\n",
      "Input: [' part', ' separate', ' member', ' full', ' very']\n",
      "Output: [' part', ' separate', ' parallel', ' well', ' member']\n",
      "\n",
      "------Layer 8------\n",
      "Dominant sub updates: [(1841, tensor(5.2167)), (3929, tensor(4.4131)), (1055, tensor(4.1130)), (593, tensor(3.2746)), (2179, tensor(3.2558)), (906, tensor(3.2462)), (251, tensor(3.0709)), (2097, tensor(2.9982)), (1637, tensor(2.9438)), (2065, tensor(2.9428))]\n",
      "Input: [' part', ' separate', ' parallel', ' well', ' member']\n",
      "Output: [' part', ' well', ' consultant', ' regular', ' full']\n",
      "\n",
      "------Layer 9------\n",
      "Dominant sub updates: [(1752, tensor(12.7507)), (3216, tensor(8.0670)), (1903, tensor(5.3074)), (854, tensor(5.1587)), (3043, tensor(4.7883)), (1589, tensor(4.2322)), (1692, tensor(3.7020)), (1584, tensor(3.5916)), (3855, tensor(3.2261)), (813, tensor(2.9576))]\n",
      "Input: [' part', ' well', ' consultant', ' regular', ' full']\n",
      "Output: [' part', ' well', ' consultant', ' member', ' non']\n",
      "\n",
      "------Layer 10------\n",
      "Dominant sub updates: [(3095, tensor(6.3257)), (2673, tensor(6.1288)), (2947, tensor(5.3637)), (1598, tensor(5.1043)), (3883, tensor(4.8446)), (1499, tensor(4.0858)), (485, tensor(3.8647)), (3348, tensor(3.8281)), (4048, tensor(3.7773)), (3243, tensor(3.7758))]\n",
      "Input: [' part', ' well', ' consultant', ' member', ' non']\n",
      "Output: [' part', ' well', ' full', ' member', ' non']\n",
      "\n",
      "------Layer 11------\n",
      "Dominant sub updates: [(668, tensor(8.0526)), (1467, tensor(6.3591)), (3184, tensor(5.9331)), (2401, tensor(5.8222)), (2918, tensor(5.1137)), (3280, tensor(4.6712)), (3014, tensor(4.5009)), (2218, tensor(3.9622)), (2207, tensor(3.6311)), (734, tensor(3.5889))]\n",
      "Input: [' part', ' well', ' full', ' member', ' non']\n",
      "Output: [' part', ' full', ' non', ' member', ' well']\n",
      "\n",
      "------Layer 12------\n",
      "Dominant sub updates: [(661, tensor(8.7009)), (591, tensor(7.1544)), (103, tensor(6.0788)), (3948, tensor(5.6012)), (97, tensor(5.5606)), (220, tensor(5.1042)), (772, tensor(4.8287)), (3118, tensor(4.4506)), (2977, tensor(4.2639)), (2342, tensor(4.2091))]\n",
      "Input: [' part', ' full', ' non', ' member', ' well']\n",
      "Output: [' consultant', ' freelance', ' part', ' full', ' non']\n",
      "\n",
      "------Layer 13------\n",
      "Dominant sub updates: [(3930, tensor(10.3437)), (3042, tensor(9.9841)), (3926, tensor(9.2597)), (2027, tensor(7.2417)), (820, tensor(6.8198)), (3210, tensor(5.9268)), (3561, tensor(4.4621)), (1489, tensor(4.4084)), (2631, tensor(4.2930)), (1651, tensor(4.0973))]\n",
      "Input: [' consultant', ' freelance', ' part', ' full', ' non']\n",
      "Output: [' freelance', ' consultant', ' professional', ' graduate', ' non']\n",
      "\n",
      "------Layer 14------\n",
      "Dominant sub updates: [(3722, tensor(10.0815)), (3645, tensor(7.7839)), (625, tensor(6.8559)), (2287, tensor(4.6026)), (3341, tensor(4.5966)), (1884, tensor(4.5358)), (2378, tensor(4.3822)), (3094, tensor(4.3342)), (202, tensor(4.1410)), (3640, tensor(4.1397))]\n",
      "Input: [' freelance', ' consultant', ' professional', ' graduate', ' non']\n",
      "Output: [' consultant', ' freelance', ' professional', ' volunteer', ' member']\n",
      "\n",
      "------Layer 15------\n",
      "Dominant sub updates: [(701, tensor(11.9902)), (109, tensor(9.4007)), (1960, tensor(7.5891)), (3863, tensor(6.3297)), (1021, tensor(5.9979)), (1167, tensor(5.7084)), (3355, tensor(5.6683)), (2149, tensor(5.5680)), (2486, tensor(5.1382)), (585, tensor(4.9187))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' volunteer', ' member']\n",
      "Output: [' consultant', ' freelance', ' professional', ' volunteer', ' doctor']\n",
      "\n",
      "------Layer 16------\n",
      "Dominant sub updates: [(918, tensor(16.5669)), (713, tensor(11.3980)), (441, tensor(9.8541)), (140, tensor(9.7215)), (3696, tensor(7.7003)), (2292, tensor(6.4687)), (3726, tensor(6.2777)), (2324, tensor(6.2387)), (412, tensor(5.6178)), (1084, tensor(5.6095))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' volunteer', ' doctor']\n",
      "Output: [' freelance', ' consultant', ' professional', ' waitress', ' volunteer']\n",
      "\n",
      "------Layer 17------\n",
      "Dominant sub updates: [(1492, tensor(18.2465)), (2518, tensor(11.8954)), (188, tensor(9.6929)), (442, tensor(8.6072)), (1918, tensor(8.5915)), (1798, tensor(8.3367)), (2016, tensor(6.6111)), (2948, tensor(6.2916)), (1828, tensor(5.7858)), (3212, tensor(5.2485))]\n",
      "Input: [' freelance', ' consultant', ' professional', ' waitress', ' volunteer']\n",
      "Output: [' consultant', ' freelance', ' professional', ' waitress', ' volunteer']\n",
      "\n",
      "------Layer 18------\n",
      "Dominant sub updates: [(919, tensor(16.1357)), (3317, tensor(10.1201)), (3511, tensor(9.3102)), (1079, tensor(8.3447)), (2286, tensor(8.1721)), (2860, tensor(7.9287)), (3331, tensor(7.5705)), (646, tensor(6.8542)), (1437, tensor(6.8537)), (1770, tensor(6.0710))]\n",
      "Input: [' consultant', ' freelance', ' professional', ' waitress', ' volunteer']\n",
      "Output: [' consultant', ' waitress', ' professional', ' freelance', ' teacher']\n",
      "\n",
      "------Layer 19------\n",
      "Dominant sub updates: [(526, tensor(18.3685)), (669, tensor(17.4086)), (2191, tensor(13.7689)), (1082, tensor(12.6830)), (1451, tensor(10.6241)), (2756, tensor(10.4825)), (2882, tensor(10.1078)), (1485, tensor(9.5944)), (3176, tensor(8.6354)), (998, tensor(7.9806))]\n",
      "Input: [' consultant', ' waitress', ' professional', ' freelance', ' teacher']\n",
      "Output: [' waitress', ' nurse', ' consultant', ' freelance', ' teacher']\n",
      "\n",
      "------Layer 20------\n",
      "Dominant sub updates: [(2820, tensor(29.4341)), (2714, tensor(19.0993)), (3518, tensor(17.8898)), (3009, tensor(16.1292)), (3818, tensor(15.2645)), (3210, tensor(12.3426)), (2003, tensor(11.9193)), (2043, tensor(11.6270)), (2850, tensor(9.9214)), (1979, tensor(9.8671))]\n",
      "Input: [' waitress', ' nurse', ' consultant', ' freelance', ' teacher']\n",
      "Output: [' nurse', ' waitress', ' teacher', ' consultant', ' freelance']\n",
      "\n",
      "------Layer 21------\n",
      "Dominant sub updates: [(3336, tensor(26.2492)), (3638, tensor(22.4138)), (2886, tensor(18.4798)), (1402, tensor(17.4918)), (178, tensor(13.6942)), (233, tensor(13.1944)), (1010, tensor(12.3246)), (3062, tensor(11.9233)), (636, tensor(11.8285)), (343, tensor(11.5148))]\n",
      "Input: [' nurse', ' waitress', ' teacher', ' consultant', ' freelance']\n",
      "Output: [' nurse', ' waitress', ' teacher', ' consultant', ' lawyer']\n",
      "\n",
      "------Layer 22------\n",
      "Dominant sub updates: [(3980, tensor(51.7502)), (2624, tensor(39.2294)), (17, tensor(24.5507)), (3015, tensor(17.3385)), (535, tensor(16.5597)), (2679, tensor(15.1725)), (1005, tensor(14.8228)), (323, tensor(14.3211)), (3516, tensor(13.7620)), (3030, tensor(13.1209))]\n",
      "Input: [' nurse', ' waitress', ' teacher', ' consultant', ' lawyer']\n",
      "Output: [' nurse', ' waitress', ' teacher', ' professional', ' lawyer']\n",
      "\n",
      "------Layer 23------\n",
      "Dominant sub updates: [(3401, tensor(37.9113)), (816, tensor(37.2731)), (2345, tensor(23.3905)), (420, tensor(20.0091)), (3383, tensor(14.0409)), (650, tensor(12.3718)), (2614, tensor(11.7772)), (2921, tensor(11.0101)), (3369, tensor(10.5555)), (1605, tensor(9.8373))]\n",
      "Input: [' nurse', ' waitress', ' teacher', ' professional', ' lawyer']\n",
      "Output: [' nurse', ' teacher', ' waitress', ' lawyer', ' consultant']\n",
      "\n",
      "Generated next token:  nurse\n"
     ]
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
