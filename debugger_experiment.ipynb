{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:52:18.076817Z",
     "start_time": "2025-02-22T19:52:13.919942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2-medium\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.mps.is_available():\n",
    "    device = 'mps'\n",
    "\n",
    "print(\"Device: \" + device)\n",
    "\n",
    "model.to(device)"
   ],
   "id": "f416ed2eeb3bdf7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T11:34:08.010063Z",
     "start_time": "2025-02-23T11:34:06.780469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input = open(\"women_in_tech.txt\", \"r\").read()\n",
    "input_ids = tokenizer.encode(input, return_tensors=\"pt\").to(device)\n",
    "target_ids = input_ids.clone()[0, 1:]\n",
    "input_ids = input_ids[:, :-1]\n",
    "\n",
    "def get_top_token_ids(rep):\n",
    "    prob = torch.softmax(rep @ model.transformer.wte.weight.T, dim=-1)\n",
    "    indices = torch.argmax(prob, dim=-1)\n",
    "    return indices\n",
    "\n",
    "num_tokens = input_ids.shape[1]\n",
    "num_layers = len(model.transformer.h)\n",
    "rep = torch.zeros((num_layers, num_tokens), device=device, dtype=torch.int64)\n",
    "def hook(_, args, output, idx):\n",
    "    token_idx = output[0].shape[1]\n",
    "    output_vec = output[0][0,:,:]\n",
    "    rep[idx] = get_top_token_ids(output_vec)\n",
    "    \n",
    "hooks = []\n",
    "for i, h in enumerate(model.transformer.h):\n",
    "    hk = h.register_forward_hook(lambda module, args, output, idx=i: hook(module, args, output, idx))\n",
    "    hooks.append(hk)\n",
    "    \n",
    "try:\n",
    "    logits = model(input_ids).logits[0]\n",
    "except Exception as e:\n",
    "    print(\"Error in model call: \",e)\n",
    "    \n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "    \n",
    "output_ids = torch.argmax(logits, dim=-1)\n",
    "stablised_layer = torch.argmin((rep - output_ids) ** 2, dim=0).to('cpu')\n",
    "output = [tokenizer.decode(int(i)) for i in output_ids]\n",
    "ip = [tokenizer.decode(int(i)) for i in input_ids[0]]\n",
    "target = [tokenizer.decode(int(i)) for i in target_ids]\n",
    "pd.DataFrame({\"input\": ip,\"output\": output, \"layer\": stablised_layer, \"target\": target})\n",
    "# pd.DataFrame({'layer':stablised_layer}).hist()"
   ],
   "id": "894da22b0a00ab51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           input       output  layer       target\n",
       "0             My       friend      0         wife\n",
       "1           wife          and      7           is\n",
       "2             is            a     15      working\n",
       "3        working           on     19           at\n",
       "4             at            a     13            a\n",
       "..           ...          ...    ...          ...\n",
       "281     learning            .     21          and\n",
       "282          and      machine     14      natural\n",
       "283      natural     language      5     language\n",
       "284     language   processing     12   processing\n",
       "285   processing            .     14            .\n",
       "\n",
       "[286 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>layer</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My</td>\n",
       "      <td>friend</td>\n",
       "      <td>0</td>\n",
       "      <td>wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wife</td>\n",
       "      <td>and</td>\n",
       "      <td>7</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "      <td>15</td>\n",
       "      <td>working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>working</td>\n",
       "      <td>on</td>\n",
       "      <td>19</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>13</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>learning</td>\n",
       "      <td>.</td>\n",
       "      <td>21</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>and</td>\n",
       "      <td>machine</td>\n",
       "      <td>14</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>natural</td>\n",
       "      <td>language</td>\n",
       "      <td>5</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>language</td>\n",
       "      <td>processing</td>\n",
       "      <td>12</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>processing</td>\n",
       "      <td>.</td>\n",
       "      <td>14</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2788a33ddd164a41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
